[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cards to Code",
    "section": "",
    "text": "A course by Max Chiswick and Ross Rheingans-Yoo on building a basic poker bot from scratch.\nThe course starts with game theory, then introduces a simplified poker setting, then the elements of the Counterfactual Regret Minimization (CFR) algorithm, and then beyond the vanilla CFR algorithm.\nThroughout the course, we’re building up code to first develop the game, and then piece by piece to develop the poker bot.\nWe end on opponent modeling and challenge problems that go beyond game theory optimal play.\nPrerequisites: Basic Python and math\nGroups/Questions: We encourage you to work through this in groups. You can chat in our Discord to discuss the course or look for others to work with.",
    "crumbs": [
      "About",
      "Home (Intro)"
    ]
  },
  {
    "objectID": "index.html#overbet.ai",
    "href": "index.html#overbet.ai",
    "title": "Cards to Code",
    "section": "Overbet.ai",
    "text": "Overbet.ai\nWe’re excited about learning through games.\nVisit Overbet.ai for daily puzzles that make you think, starting with Rock Paper Scissors.\nWe’ll have more advanced courses available soon.",
    "crumbs": [
      "About",
      "Home (Intro)"
    ]
  },
  {
    "objectID": "index.html#why-poker",
    "href": "index.html#why-poker",
    "title": "Cards to Code",
    "section": "Why poker?",
    "text": "Why poker?\nLet’s split this into two questions.\n\nWhy play poker?\nGames of incomplete information like poker are most similar to real-life settings. Incomplete information means that there is some hidden information – in Texas Hold’em this is the opponent cards and the yet to be revealed board cards.\nThis means we need to infer our opponents’ hands and understand the probabilities of the cards that we can’t see.\nPoker is useful from a math perspective – probability, expected value, risk, and bankroll management are all important skills.\nIt’s also useful from a psychological perspective – emotional control, reading opponents, and adapting to other players are all valuable.\nWe learn to make decisions and focus on the quality of the decision, rather than the results.\n\n\nWhy build a poker bot?\nPoker has clear rules and structure, so we can apply reinforcement learning where the rewards are the profits in the game. Reinforcement learning, game theory, and Monte Carlo methods are applicable across many domains.\nHere we mainly focus on a simplified poker game that can be solved in under a minute, but the same core principles apply for scaled up versions that are much larger and more complex, though they will also involve approximating states of the game.\nThe richness of the game is an ideal testbed for decision making under uncertainty, probabilistic reasoning, and taking actions that can have both immediate and longer horizon consequences.\nWe can use the bot solutions to gain insights from the underlying game itself. For example, you’ll see that bots automatically learn to bluff, showing that this is a theoretically correct play and not a “loss leader” just to get more action later.\nBeyond building a basic bot, there is a broad area for further research, including agent evaluation, opponent modeling, building an LLM model on top of the traditional poker agent, and intepretability of the agent.",
    "crumbs": [
      "About",
      "Home (Intro)"
    ]
  },
  {
    "objectID": "index.html#ai-agents-in-2024",
    "href": "index.html#ai-agents-in-2024",
    "title": "Cards to Code",
    "section": "AI agents in 2024",
    "text": "AI agents in 2024\nLLM-based AI agents are very popular in 2024. The poker bot we’re building here is different and uses the classic AI method of reinforcement learning, where the goal is to maximize long-term reward given feedback from the environment (i.e. maximizing winnings in a poker game).\nThe poker bot learns how to make optimal decisions given a state of the game by repeatedly playing the game against itself and optimizing the strategy over time.\nLLM agents generally use large amounts of text data to understand and generate human-like language based on patterns in the data, which could include strategy in a game like poker.\nSo is RL still relevant? Yes! OpenAI recently released their o1 chain of thought model:\n\nOur large-scale reinforcement learning algorithm teaches the model how to think productively using its chain of thought in a highly data-efficient training process.\n\nIn chain of thought, each step in the reasoning process can be seen as a state with possible actions. RLHF (Reinforcement Learning from Human Feedback) is also a popular technique for LLM agents where a human acts as the reward signal to shape a model’s outputs.\nHybrid approaches seem promising and may be a future direction for poker agents as well.",
    "crumbs": [
      "About",
      "Home (Intro)"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "C2C: About",
    "section": "",
    "text": "We developed Cards to Code as a foundational course on building a functional poker bot after running an AI Poker Camp course in San Francisco in summer 2024.\nCheck out Overbet.ai (under development) and Poker Camp."
  },
  {
    "objectID": "about.html#about-us",
    "href": "about.html#about-us",
    "title": "C2C: About",
    "section": "",
    "text": "We developed Cards to Code as a foundational course on building a functional poker bot after running an AI Poker Camp course in San Francisco in summer 2024.\nCheck out Overbet.ai (under development) and Poker Camp."
  },
  {
    "objectID": "about.html#inspiration",
    "href": "about.html#inspiration",
    "title": "C2C: About",
    "section": "Inspiration",
    "text": "Inspiration\nSome inspiration:\n\nNand to Tetris: Building a Modern Computer From First Principles\nNeural Networks: Zero to Hero: A course by Andrej Karpathy on building neural networks, from scratch, in code\nfast.ai’s Practical Deep Learning: A free course designed for people with some coding experience, who want to learn how to apply deep learning and machine learning to practical problems"
  }
]